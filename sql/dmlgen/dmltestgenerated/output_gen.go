// Code generated by corestoreio/pkg/util/codegen. DO NOT EDIT.
// Generated by sql/dmlgen. DO NOT EDIT.
// +build !ignore
// +build !ignored

package dmltestgenerated

import (
	"context"
	"database/sql"
	"fmt"
	"io"
	"time"

	"github.com/corestoreio/errors"
	"github.com/corestoreio/pkg/sql/ddl"
	"github.com/corestoreio/pkg/sql/dml"
	"github.com/corestoreio/pkg/storage/null"
	"github.com/corestoreio/pkg/util/cstrace"
)

// CatalogProductIndexEAVDecimalIDX represents a single row for DB table
// catalog_product_index_eav_decimal_idx. Auto generated.
// Table comment: Catalog Product EAV Decimal Indexer Index Table
type CatalogProductIndexEAVDecimalIDX struct {
	EntityID    uint32       // entity_id int(10) unsigned NOT NULL PRI   "Entity ID"
	AttributeID uint32       // attribute_id smallint(5) unsigned NOT NULL PRI   "Attribute ID"
	StoreID     uint32       // store_id smallint(5) unsigned NOT NULL PRI   "Store ID"
	SourceID    uint32       // source_id int(10) unsigned NOT NULL PRI DEFAULT '0'  "Original entity Id for attribute value"
	Value       null.Decimal // value decimal(12,4) NOT NULL MUL   "Value"
}

// CoreConfiguration represents a single row for DB table core_configuration.
// Auto generated.
// Table comment: Config Data
//easyjson:json
type CoreConfiguration struct {
	ConfigID  uint32      `json:"config_id,omitempty" max_len:"10"`  // config_id int(10) unsigned NOT NULL PRI  auto_increment "Id"
	Scope     string      `json:"scope,omitempty" max_len:"8"`       // scope varchar(8) NOT NULL MUL DEFAULT ''default''  "Scope"
	ScopeID   int32       `json:"scope_id" xml:"scope_id"`           // scope_id int(11) NOT NULL  DEFAULT '0'  "Scope Id"
	Expires   null.Time   `json:"expires,omitempty" `                // expires datetime NULL  DEFAULT 'NULL'  "Value expiration time"
	Path      string      `json:"x_path" xml:"y_path" max_len:"255"` // path varchar(255) NOT NULL  DEFAULT ''general''  "Config Path overwritten"
	Value     null.String `json:"value,omitempty" max_len:"65535"`   // value text NULL  DEFAULT 'NULL'  "Value"
	VersionTs time.Time   `json:"version_ts,omitempty" `             // version_ts timestamp(6) NOT NULL   STORED GENERATED "Timestamp Start Versioning"
	VersionTe time.Time   `json:"version_te,omitempty" `             // version_te timestamp(6) NOT NULL PRI  STORED GENERATED "Timestamp End Versioning"
}

// CustomerAddressEntity represents a single row for DB table
// customer_address_entity. Auto generated.
// Table comment: Customer Address Entity
//easyjson:json
type CustomerAddressEntity struct {
	EntityID    uint32      `max_len:"10"` // entity_id int(10) unsigned NOT NULL PRI  auto_increment "Entity ID"
	IncrementID null.String `max_len:"50"` // increment_id varchar(50) NULL  DEFAULT 'NULL'  "Increment Id"
	ParentID    null.Uint32 `max_len:"10"` // parent_id int(10) unsigned NULL MUL DEFAULT 'NULL'  "Parent ID"
	CreatedAt   time.Time   // created_at timestamp NOT NULL  DEFAULT 'current_timestamp()'  "Created At"
	UpdatedAt   time.Time   // updated_at timestamp NOT NULL  DEFAULT 'current_timestamp()' on update current_timestamp() "Updated At"
	IsActive    bool        `max_len:"5"`     // is_active smallint(5) unsigned NOT NULL  DEFAULT '1'  "Is Active"
	City        string      `max_len:"255"`   // city varchar(255) NOT NULL    "City"
	Company     null.String `max_len:"255"`   // company varchar(255) NULL  DEFAULT 'NULL'  "Company"
	CountryID   string      `max_len:"255"`   // country_id varchar(255) NOT NULL    "Country"
	Firstname   string      `max_len:"255"`   // firstname varchar(255) NOT NULL    "First Name"
	Lastname    string      `max_len:"255"`   // lastname varchar(255) NOT NULL    "Last Name"
	Postcode    null.String `max_len:"255"`   // postcode varchar(255) NULL  DEFAULT 'NULL'  "Zip/Postal Code"
	Region      null.String `max_len:"255"`   // region varchar(255) NULL  DEFAULT 'NULL'  "State/Province"
	Street      string      `max_len:"65535"` // street text NOT NULL    "Street Address"
}

type customerEntityRelations struct {
	parent                  *CustomerEntity
	CustomerAddressEntities *CustomerAddressEntities // Reversed 1:M customer_entity.entity_id => customer_address_entity.parent_id
}

func (e *CustomerEntity) setRelationParent() {
	if e.Relations != nil && e.Relations.parent == nil {
		e.Relations.parent = e
	}
}

func (e *CustomerEntity) NewRelations() *customerEntityRelations {
	e.Relations = &customerEntityRelations{parent: e}
	return e.Relations
}

// CustomerEntity represents a single row for DB table customer_entity. Auto
// generated.
// Table comment: Customer Entity
//easyjson:json
type CustomerEntity struct {
	EntityID         uint32      `max_len:"10"`  // entity_id int(10) unsigned NOT NULL PRI  auto_increment "Entity ID"
	WebsiteID        null.Uint32 `max_len:"5"`   // website_id smallint(5) unsigned NULL MUL DEFAULT 'NULL'  "Website ID"
	Email            null.String `max_len:"255"` // email varchar(255) NULL MUL DEFAULT 'NULL'  "Email"
	GroupID          uint32      `max_len:"5"`   // group_id smallint(5) unsigned NOT NULL  DEFAULT '0'  "Group ID"
	StoreID          null.Uint32 `max_len:"5"`   // store_id smallint(5) unsigned NULL MUL DEFAULT '0'  "Store ID"
	CreatedAt        time.Time   // created_at timestamp NOT NULL  DEFAULT 'current_timestamp()'  "Created At"
	UpdatedAt        time.Time   // updated_at timestamp NOT NULL  DEFAULT 'current_timestamp()' on update current_timestamp() "Updated At"
	IsActive         bool        `max_len:"5"`   // is_active smallint(5) unsigned NOT NULL  DEFAULT '1'  "Is Active"
	CreatedIn        null.String `max_len:"255"` // created_in varchar(255) NULL  DEFAULT 'NULL'  "Created From"
	Firstname        null.String `max_len:"255"` // firstname varchar(255) NULL MUL DEFAULT 'NULL'  "First Name"
	Lastname         null.String `max_len:"255"` // lastname varchar(255) NULL MUL DEFAULT 'NULL'  "Last Name"
	Dob              null.Time   // dob date NULL  DEFAULT 'NULL'  "Date of Birth"
	passwordHash     null.String `max_len:"128"` // password_hash varchar(128) NULL  DEFAULT 'NULL'  "Password_hash"
	RpToken          null.String `max_len:"128"` // rp_token varchar(128) NULL  DEFAULT 'NULL'  "Reset password token"
	RpTokenCreatedAt null.Time   // rp_token_created_at datetime NULL  DEFAULT 'NULL'  "Reset password token creation time"
	DefaultBilling   null.Uint32 `max_len:"10"` // default_billing int(10) unsigned NULL  DEFAULT 'NULL'  "Default Billing Address"
	DefaultShipping  null.Uint32 `max_len:"10"` // default_shipping int(10) unsigned NULL  DEFAULT 'NULL'  "Default Shipping Address"
	Gender           null.Uint32 `max_len:"5"`  // gender smallint(5) unsigned NULL  DEFAULT 'NULL'  "Gender"
	Relations        *customerEntityRelations
}

// DmlgenTypes represents a single row for DB table dmlgen_types. Auto generated.
// // Just another comment.
//easyjson:json
type DmlgenTypes struct {
	ID             int32        `json:"id,omitempty"  max_len:"10"`                     // id int(11) NOT NULL PRI  auto_increment ""
	ColBigint1     null.Int64   `json:"col_bigint_1,omitempty"  max_len:"19"`           // col_bigint_1 bigint(20) NULL  DEFAULT 'NULL'  ""
	ColBigint2     int64        `json:"col_bigint_2,omitempty"  max_len:"19"`           // col_bigint_2 bigint(20) NOT NULL  DEFAULT '0'  ""
	ColBigint3     null.Uint64  `json:"col_bigint_3,omitempty"  max_len:"20"`           // col_bigint_3 bigint(20) unsigned NULL  DEFAULT 'NULL'  ""
	ColBigint4     uint64       `json:"col_bigint_4,omitempty"  max_len:"20"`           // col_bigint_4 bigint(20) unsigned NOT NULL  DEFAULT '0'  ""
	ColBlob        []byte       `json:"col_blob,omitempty"  max_len:"65535"`            // col_blob blob NULL  DEFAULT 'NULL'  ""
	ColDate1       null.Time    `json:"col_date_1,omitempty"  `                         // col_date_1 date NULL  DEFAULT 'NULL'  ""
	ColDate2       time.Time    `json:"col_date_2,omitempty"  `                         // col_date_2 date NOT NULL  DEFAULT ''0000-00-00''  ""
	ColDatetime1   null.Time    `json:"col_datetime_1,omitempty"  `                     // col_datetime_1 datetime NULL  DEFAULT 'NULL'  ""
	ColDatetime2   time.Time    `json:"col_datetime_2,omitempty"  `                     // col_datetime_2 datetime NOT NULL  DEFAULT ''0000-00-00 00:00:00''  ""
	ColDecimal101  null.Decimal `json:"col_decimal_10_1,omitempty"  max_len:"10"`       // col_decimal_10_1 decimal(10,1) unsigned NULL  DEFAULT 'NULL'  ""
	ColDecimal124  null.Decimal `json:"col_decimal_12_4,omitempty"  max_len:"12"`       // col_decimal_12_4 decimal(12,4) NULL  DEFAULT 'NULL'  ""
	PriceA124      null.Decimal `json:"price_a_12_4,omitempty"  max_len:"12"`           // price_a_12_4 decimal(12,4) NULL  DEFAULT 'NULL'  ""
	PriceB124      null.Decimal `json:"price_b_12_4,omitempty"  max_len:"12"`           // price_b_12_4 decimal(12,4) NOT NULL  DEFAULT '0.0000'  ""
	ColDecimal123  null.Decimal `json:"col_decimal_12_3,omitempty"  max_len:"12"`       // col_decimal_12_3 decimal(12,3) NOT NULL  DEFAULT '0.000'  ""
	ColDecimal206  null.Decimal `json:"col_decimal_20_6,omitempty"  max_len:"20"`       // col_decimal_20_6 decimal(20,6) NOT NULL  DEFAULT '0.000000'  ""
	ColDecimal2412 null.Decimal `json:"col_decimal_24_12,omitempty"  max_len:"24"`      // col_decimal_24_12 decimal(24,12) NOT NULL  DEFAULT '0.000000000000'  ""
	ColInt1        null.Int32   `json:"col_int_1,omitempty"  max_len:"10"`              // col_int_1 int(10) NULL  DEFAULT 'NULL'  ""
	ColInt2        int32        `json:"col_int_2,omitempty"  max_len:"10"`              // col_int_2 int(10) NOT NULL  DEFAULT '0'  ""
	ColInt3        null.Uint32  `json:"col_int_3,omitempty"  max_len:"10"`              // col_int_3 int(10) unsigned NULL  DEFAULT 'NULL'  ""
	ColInt4        uint32       `json:"col_int_4,omitempty"  max_len:"10"`              // col_int_4 int(10) unsigned NOT NULL  DEFAULT '0'  ""
	ColLongtext1   null.String  `json:"col_longtext_1,omitempty"  max_len:"4294967295"` // col_longtext_1 longtext NULL  DEFAULT 'NULL'  ""
	ColLongtext2   string       `json:"col_longtext_2,omitempty"  max_len:"4294967295"` // col_longtext_2 longtext NOT NULL  DEFAULT ''''  ""
	ColMediumblob  []byte       `json:"col_mediumblob,omitempty"  max_len:"16777215"`   // col_mediumblob mediumblob NULL  DEFAULT 'NULL'  ""
	ColMediumtext1 null.String  `json:"col_mediumtext_1,omitempty"  max_len:"16777215"` // col_mediumtext_1 mediumtext NULL  DEFAULT 'NULL'  ""
	ColMediumtext2 string       `json:"col_mediumtext_2,omitempty"  max_len:"16777215"` // col_mediumtext_2 mediumtext NOT NULL  DEFAULT ''''  ""
	ColSmallint1   null.Int32   `json:"col_smallint_1,omitempty"  max_len:"5"`          // col_smallint_1 smallint(5) NULL  DEFAULT 'NULL'  ""
	ColSmallint2   int32        `json:"col_smallint_2,omitempty"  max_len:"5"`          // col_smallint_2 smallint(5) NOT NULL  DEFAULT '0'  ""
	ColSmallint3   null.Uint32  `json:"col_smallint_3,omitempty"  max_len:"5"`          // col_smallint_3 smallint(5) unsigned NULL  DEFAULT 'NULL'  ""
	ColSmallint4   uint32       `json:"col_smallint_4,omitempty"  max_len:"5"`          // col_smallint_4 smallint(5) unsigned NOT NULL  DEFAULT '0'  ""
	HasSmallint5   bool         `json:"has_smallint_5,omitempty"  max_len:"5"`          // has_smallint_5 smallint(5) unsigned NOT NULL  DEFAULT '0'  ""
	IsSmallint5    null.Bool    `json:"is_smallint_5,omitempty"  max_len:"5"`           // is_smallint_5 smallint(5) NULL  DEFAULT 'NULL'  ""
	ColText        null.String  `json:"col_text,omitempty"  max_len:"65535"`            // col_text text NULL  DEFAULT 'NULL'  ""
	ColTimestamp1  time.Time    `json:"col_timestamp_1,omitempty"  `                    // col_timestamp_1 timestamp NOT NULL  DEFAULT 'current_timestamp()'  ""
	ColTimestamp2  null.Time    `json:"col_timestamp_2,omitempty"  `                    // col_timestamp_2 timestamp NULL  DEFAULT 'NULL'  ""
	ColTinyint1    int32        `json:"col_tinyint_1,omitempty"  max_len:"3"`           // col_tinyint_1 tinyint(1) NOT NULL  DEFAULT '0'  ""
	ColVarchar1    string       `json:"col_varchar_1,omitempty"  max_len:"1"`           // col_varchar_1 varchar(1) NOT NULL  DEFAULT ''0''  ""
	ColVarchar100  null.String  `json:"col_varchar_100,omitempty"  max_len:"100"`       // col_varchar_100 varchar(100) NULL  DEFAULT 'NULL'  ""
	ColVarchar16   string       `json:"col_varchar_16,omitempty"  max_len:"16"`         // col_varchar_16 varchar(16) NOT NULL  DEFAULT ''de_DE''  ""
	ColChar1       null.String  `json:"col_char_1,omitempty"  max_len:"21"`             // col_char_1 char(21) NULL  DEFAULT 'NULL'  ""
	ColChar2       string       `json:"col_char_2,omitempty"  max_len:"17"`             // col_char_2 char(17) NOT NULL  DEFAULT ''xchar''  ""
}

// SalesOrderStatusState represents a single row for DB table
// sales_order_status_state. Auto generated.
// Table comment: Sales Order Status Table
//easyjson:json
type SalesOrderStatusState struct {
	Status         string `max_len:"32"` // status varchar(32) NOT NULL PRI   "Status"
	State          string `max_len:"32"` // state varchar(32) NOT NULL PRI   "Label"
	IsDefault      bool   `max_len:"5"`  // is_default smallint(5) unsigned NOT NULL  DEFAULT '0'  "Is Default"
	VisibleOnFront uint32 `max_len:"5"`  // visible_on_front smallint(5) unsigned NOT NULL  DEFAULT '0'  "Visible on front"
}

// ViewCustomerAutoIncrement represents a single row for DB table
// view_customer_auto_increment. Auto generated.
// Table comment: VIEW
//easyjson:json
type ViewCustomerAutoIncrement struct {
	CeEntityID uint32      `max_len:"10"`  // ce_entity_id int(10) unsigned NOT NULL  DEFAULT '0'  "Entity ID"
	Email      null.String `max_len:"255"` // email varchar(255) NULL  DEFAULT 'NULL'  "Email"
	Firstname  string      `max_len:"255"` // firstname varchar(255) NOT NULL    "First Name"
	Lastname   string      `max_len:"255"` // lastname varchar(255) NOT NULL    "Last Name"
	City       string      `max_len:"255"` // city varchar(255) NOT NULL    "City"
}

// ViewCustomerNoAutoIncrement represents a single row for DB table
// view_customer_no_auto_increment. Auto generated.
// Table comment: VIEW
//easyjson:json
type ViewCustomerNoAutoIncrement struct {
	Email     null.String `max_len:"255"` // email varchar(255) NULL  DEFAULT 'NULL'  "Email"
	Firstname string      `max_len:"255"` // firstname varchar(255) NOT NULL    "First Name"
	Lastname  string      `max_len:"255"` // lastname varchar(255) NOT NULL    "Last Name"
	City      string      `max_len:"255"` // city varchar(255) NOT NULL    "City"
}

// TableName constants define the names of all tables.
const (
	TableNameCatalogProductIndexEAVDecimalIDX = "catalog_product_index_eav_decimal_idx"
	TableNameCoreConfiguration                = "core_configuration"
	TableNameCustomerAddressEntity            = "customer_address_entity"
	TableNameCustomerEntity                   = "customer_entity"
	TableNameDmlgenTypes                      = "dmlgen_types"
	TableNameSalesOrderStatusState            = "sales_order_status_state"
	TableNameViewCustomerAutoIncrement        = "view_customer_auto_increment"
	TableNameViewCustomerNoAutoIncrement      = "view_customer_no_auto_increment"
)

// Columns struct provides for all tables the name of the columns. Allows type
// safety.
var Columns = struct {
	CatalogProductIndexEAVDecimalIDX struct {
		EntityID    string
		AttributeID string
		StoreID     string
		SourceID    string
		Value       string
	}
	CoreConfiguration struct {
		ConfigID  string
		Scope     string
		ScopeID   string
		Expires   string
		Path      string
		Value     string
		VersionTs string
		VersionTe string
	}
	CustomerAddressEntity struct {
		EntityID    string
		IncrementID string
		ParentID    string
		CreatedAt   string
		UpdatedAt   string
		IsActive    string
		City        string
		Company     string
		CountryID   string
		Firstname   string
		Lastname    string
		Postcode    string
		Region      string
		Street      string
	}
	CustomerEntity struct {
		EntityID         string
		WebsiteID        string
		Email            string
		GroupID          string
		StoreID          string
		CreatedAt        string
		UpdatedAt        string
		IsActive         string
		CreatedIn        string
		Firstname        string
		Lastname         string
		Dob              string
		PasswordHash     string
		RpToken          string
		RpTokenCreatedAt string
		DefaultBilling   string
		DefaultShipping  string
		Gender           string
	}
	DmlgenTypes struct {
		ID             string
		ColBigint1     string
		ColBigint2     string
		ColBigint3     string
		ColBigint4     string
		ColBlob        string
		ColDate1       string
		ColDate2       string
		ColDatetime1   string
		ColDatetime2   string
		ColDecimal101  string
		ColDecimal124  string
		PriceA124      string
		PriceB124      string
		ColDecimal123  string
		ColDecimal206  string
		ColDecimal2412 string
		ColInt1        string
		ColInt2        string
		ColInt3        string
		ColInt4        string
		ColLongtext1   string
		ColLongtext2   string
		ColMediumblob  string
		ColMediumtext1 string
		ColMediumtext2 string
		ColSmallint1   string
		ColSmallint2   string
		ColSmallint3   string
		ColSmallint4   string
		HasSmallint5   string
		IsSmallint5    string
		ColText        string
		ColTimestamp1  string
		ColTimestamp2  string
		ColTinyint1    string
		ColVarchar1    string
		ColVarchar100  string
		ColVarchar16   string
		ColChar1       string
		ColChar2       string
	}
	SalesOrderStatusState struct {
		Status         string
		State          string
		IsDefault      string
		VisibleOnFront string
	}
	ViewCustomerAutoIncrement struct {
		CeEntityID string
		Email      string
		Firstname  string
		Lastname   string
		City       string
	}
	ViewCustomerNoAutoIncrement struct {
		Email     string
		Firstname string
		Lastname  string
		City      string
	}
}{
	CatalogProductIndexEAVDecimalIDX: struct {
		EntityID    string
		AttributeID string
		StoreID     string
		SourceID    string
		Value       string
	}{
		EntityID:    "entity_id",
		AttributeID: "attribute_id",
		StoreID:     "store_id",
		SourceID:    "source_id",
		Value:       "value",
	},
	CoreConfiguration: struct {
		ConfigID  string
		Scope     string
		ScopeID   string
		Expires   string
		Path      string
		Value     string
		VersionTs string
		VersionTe string
	}{
		ConfigID:  "config_id",
		Scope:     "scope",
		ScopeID:   "scope_id",
		Expires:   "expires",
		Path:      "path",
		Value:     "value",
		VersionTs: "version_ts",
		VersionTe: "version_te",
	},
	CustomerAddressEntity: struct {
		EntityID    string
		IncrementID string
		ParentID    string
		CreatedAt   string
		UpdatedAt   string
		IsActive    string
		City        string
		Company     string
		CountryID   string
		Firstname   string
		Lastname    string
		Postcode    string
		Region      string
		Street      string
	}{
		EntityID:    "entity_id",
		IncrementID: "increment_id",
		ParentID:    "parent_id",
		CreatedAt:   "created_at",
		UpdatedAt:   "updated_at",
		IsActive:    "is_active",
		City:        "city",
		Company:     "company",
		CountryID:   "country_id",
		Firstname:   "firstname",
		Lastname:    "lastname",
		Postcode:    "postcode",
		Region:      "region",
		Street:      "street",
	},
	CustomerEntity: struct {
		EntityID         string
		WebsiteID        string
		Email            string
		GroupID          string
		StoreID          string
		CreatedAt        string
		UpdatedAt        string
		IsActive         string
		CreatedIn        string
		Firstname        string
		Lastname         string
		Dob              string
		PasswordHash     string
		RpToken          string
		RpTokenCreatedAt string
		DefaultBilling   string
		DefaultShipping  string
		Gender           string
	}{
		EntityID:         "entity_id",
		WebsiteID:        "website_id",
		Email:            "email",
		GroupID:          "group_id",
		StoreID:          "store_id",
		CreatedAt:        "created_at",
		UpdatedAt:        "updated_at",
		IsActive:         "is_active",
		CreatedIn:        "created_in",
		Firstname:        "firstname",
		Lastname:         "lastname",
		Dob:              "dob",
		PasswordHash:     "password_hash",
		RpToken:          "rp_token",
		RpTokenCreatedAt: "rp_token_created_at",
		DefaultBilling:   "default_billing",
		DefaultShipping:  "default_shipping",
		Gender:           "gender",
	},
	DmlgenTypes: struct {
		ID             string
		ColBigint1     string
		ColBigint2     string
		ColBigint3     string
		ColBigint4     string
		ColBlob        string
		ColDate1       string
		ColDate2       string
		ColDatetime1   string
		ColDatetime2   string
		ColDecimal101  string
		ColDecimal124  string
		PriceA124      string
		PriceB124      string
		ColDecimal123  string
		ColDecimal206  string
		ColDecimal2412 string
		ColInt1        string
		ColInt2        string
		ColInt3        string
		ColInt4        string
		ColLongtext1   string
		ColLongtext2   string
		ColMediumblob  string
		ColMediumtext1 string
		ColMediumtext2 string
		ColSmallint1   string
		ColSmallint2   string
		ColSmallint3   string
		ColSmallint4   string
		HasSmallint5   string
		IsSmallint5    string
		ColText        string
		ColTimestamp1  string
		ColTimestamp2  string
		ColTinyint1    string
		ColVarchar1    string
		ColVarchar100  string
		ColVarchar16   string
		ColChar1       string
		ColChar2       string
	}{
		ID:             "id",
		ColBigint1:     "col_bigint_1",
		ColBigint2:     "col_bigint_2",
		ColBigint3:     "col_bigint_3",
		ColBigint4:     "col_bigint_4",
		ColBlob:        "col_blob",
		ColDate1:       "col_date_1",
		ColDate2:       "col_date_2",
		ColDatetime1:   "col_datetime_1",
		ColDatetime2:   "col_datetime_2",
		ColDecimal101:  "col_decimal_10_1",
		ColDecimal124:  "col_decimal_12_4",
		PriceA124:      "price_a_12_4",
		PriceB124:      "price_b_12_4",
		ColDecimal123:  "col_decimal_12_3",
		ColDecimal206:  "col_decimal_20_6",
		ColDecimal2412: "col_decimal_24_12",
		ColInt1:        "col_int_1",
		ColInt2:        "col_int_2",
		ColInt3:        "col_int_3",
		ColInt4:        "col_int_4",
		ColLongtext1:   "col_longtext_1",
		ColLongtext2:   "col_longtext_2",
		ColMediumblob:  "col_mediumblob",
		ColMediumtext1: "col_mediumtext_1",
		ColMediumtext2: "col_mediumtext_2",
		ColSmallint1:   "col_smallint_1",
		ColSmallint2:   "col_smallint_2",
		ColSmallint3:   "col_smallint_3",
		ColSmallint4:   "col_smallint_4",
		HasSmallint5:   "has_smallint_5",
		IsSmallint5:    "is_smallint_5",
		ColText:        "col_text",
		ColTimestamp1:  "col_timestamp_1",
		ColTimestamp2:  "col_timestamp_2",
		ColTinyint1:    "col_tinyint_1",
		ColVarchar1:    "col_varchar_1",
		ColVarchar100:  "col_varchar_100",
		ColVarchar16:   "col_varchar_16",
		ColChar1:       "col_char_1",
		ColChar2:       "col_char_2",
	},
	SalesOrderStatusState: struct {
		Status         string
		State          string
		IsDefault      string
		VisibleOnFront string
	}{
		Status:         "status",
		State:          "state",
		IsDefault:      "is_default",
		VisibleOnFront: "visible_on_front",
	},
	ViewCustomerAutoIncrement: struct {
		CeEntityID string
		Email      string
		Firstname  string
		Lastname   string
		City       string
	}{
		CeEntityID: "ce_entity_id",
		Email:      "email",
		Firstname:  "firstname",
		Lastname:   "lastname",
		City:       "city",
	},
	ViewCustomerNoAutoIncrement: struct {
		Email     string
		Firstname string
		Lastname  string
		City      string
	}{
		Email:     "email",
		Firstname: "firstname",
		Lastname:  "lastname",
		City:      "city",
	},
}

// Event functions are getting dispatched during before or after handling a
// collection or an entity.
// Context is always non-nil but either collection or entity pointer will be set.
type (
	EventCatalogProductIndexEAVDecimalIDXFn func(context.Context, *CatalogProductIndexEAVDecimalIDXes, *CatalogProductIndexEAVDecimalIDX) error
	EventCoreConfigurationFn                func(context.Context, *CoreConfigurations, *CoreConfiguration) error
	EventCustomerAddressEntityFn            func(context.Context, *CustomerAddressEntities, *CustomerAddressEntity) error
	EventCustomerEntityFn                   func(context.Context, *CustomerEntities, *CustomerEntity) error
	EventDmlgenTypesFn                      func(context.Context, *DmlgenTypesCollection, *DmlgenTypes) error
	EventSalesOrderStatusStateFn            func(context.Context, *SalesOrderStatusStates, *SalesOrderStatusState) error
	EventViewCustomerAutoIncrementFn        func(context.Context, *ViewCustomerAutoIncrements, *ViewCustomerAutoIncrement) error
	EventViewCustomerNoAutoIncrementFn      func(context.Context, *ViewCustomerNoAutoIncrements, *ViewCustomerNoAutoIncrement) error
)

// DBMOption provides various options to the DBM object.
type DBMOption struct {
	Trace                                     cstrace.Tracer
	TableOptions                              []ddl.TableOption // gets applied at the beginning
	TableOptionsAfter                         []ddl.TableOption // gets applied at the end
	InitSelectFn                              func(*dml.Select) *dml.Select
	InitUpdateFn                              func(*dml.Update) *dml.Update
	InitDeleteFn                              func(*dml.Delete) *dml.Delete
	InitInsertFn                              func(*dml.Insert) *dml.Insert
	eventCatalogProductIndexEAVDecimalIDXFunc [dml.EventFlagMax][]EventCatalogProductIndexEAVDecimalIDXFn
	eventCoreConfigurationFunc                [dml.EventFlagMax][]EventCoreConfigurationFn
	eventCustomerAddressEntityFunc            [dml.EventFlagMax][]EventCustomerAddressEntityFn
	eventCustomerEntityFunc                   [dml.EventFlagMax][]EventCustomerEntityFn
	eventDmlgenTypesFunc                      [dml.EventFlagMax][]EventDmlgenTypesFn
	eventSalesOrderStatusStateFunc            [dml.EventFlagMax][]EventSalesOrderStatusStateFn
	eventViewCustomerAutoIncrementFunc        [dml.EventFlagMax][]EventViewCustomerAutoIncrementFn
	eventViewCustomerNoAutoIncrementFunc      [dml.EventFlagMax][]EventViewCustomerNoAutoIncrementFn
}

// AddEventCatalogProductIndexEAVDecimalIDX adds a specific defined event call
// back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCatalogProductIndexEAVDecimalIDX(event dml.EventFlag, fn EventCatalogProductIndexEAVDecimalIDXFn) *DBMOption {
	o.eventCatalogProductIndexEAVDecimalIDXFunc[event] = append(o.eventCatalogProductIndexEAVDecimalIDXFunc[event], fn)
	return o
}

// AddEventCoreConfiguration adds a specific defined event call back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCoreConfiguration(event dml.EventFlag, fn EventCoreConfigurationFn) *DBMOption {
	o.eventCoreConfigurationFunc[event] = append(o.eventCoreConfigurationFunc[event], fn)
	return o
}

// AddEventCustomerAddressEntity adds a specific defined event call back to the
// DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCustomerAddressEntity(event dml.EventFlag, fn EventCustomerAddressEntityFn) *DBMOption {
	o.eventCustomerAddressEntityFunc[event] = append(o.eventCustomerAddressEntityFunc[event], fn)
	return o
}

// AddEventCustomerEntity adds a specific defined event call back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCustomerEntity(event dml.EventFlag, fn EventCustomerEntityFn) *DBMOption {
	o.eventCustomerEntityFunc[event] = append(o.eventCustomerEntityFunc[event], fn)
	return o
}

// AddEventDmlgenTypes adds a specific defined event call back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventDmlgenTypes(event dml.EventFlag, fn EventDmlgenTypesFn) *DBMOption {
	o.eventDmlgenTypesFunc[event] = append(o.eventDmlgenTypesFunc[event], fn)
	return o
}

// AddEventSalesOrderStatusState adds a specific defined event call back to the
// DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventSalesOrderStatusState(event dml.EventFlag, fn EventSalesOrderStatusStateFn) *DBMOption {
	o.eventSalesOrderStatusStateFunc[event] = append(o.eventSalesOrderStatusStateFunc[event], fn)
	return o
}

// AddEventViewCustomerAutoIncrement adds a specific defined event call back to
// the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventViewCustomerAutoIncrement(event dml.EventFlag, fn EventViewCustomerAutoIncrementFn) *DBMOption {
	o.eventViewCustomerAutoIncrementFunc[event] = append(o.eventViewCustomerAutoIncrementFunc[event], fn)
	return o
}

// AddEventViewCustomerNoAutoIncrement adds a specific defined event call back to
// the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventViewCustomerNoAutoIncrement(event dml.EventFlag, fn EventViewCustomerNoAutoIncrementFn) *DBMOption {
	o.eventViewCustomerNoAutoIncrementFunc[event] = append(o.eventViewCustomerNoAutoIncrementFunc[event], fn)
	return o
}

// DBM defines the DataBaseManagement object for the tables
// catalog_product_index_eav_decimal_idx, core_configuration,
// customer_address_entity, customer_entity, dmlgen_types,
// sales_order_status_state, view_customer_auto_increment,
// view_customer_no_auto_increment
type DBM struct {
	*ddl.Tables
	option DBMOption
}

func (dbm DBM) eventCatalogProductIndexEAVDecimalIDXFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *CatalogProductIndexEAVDecimalIDXes, e *CatalogProductIndexEAVDecimalIDX) error {
	if len(dbm.option.eventCatalogProductIndexEAVDecimalIDXFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventCatalogProductIndexEAVDecimalIDXFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventCoreConfigurationFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *CoreConfigurations, e *CoreConfiguration) error {
	if len(dbm.option.eventCoreConfigurationFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventCoreConfigurationFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventCustomerAddressEntityFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *CustomerAddressEntities, e *CustomerAddressEntity) error {
	if len(dbm.option.eventCustomerAddressEntityFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventCustomerAddressEntityFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventCustomerEntityFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *CustomerEntities, e *CustomerEntity) error {
	if len(dbm.option.eventCustomerEntityFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventCustomerEntityFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventDmlgenTypesFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *DmlgenTypesCollection, e *DmlgenTypes) error {
	if len(dbm.option.eventDmlgenTypesFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventDmlgenTypesFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventSalesOrderStatusStateFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *SalesOrderStatusStates, e *SalesOrderStatusState) error {
	if len(dbm.option.eventSalesOrderStatusStateFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventSalesOrderStatusStateFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventViewCustomerAutoIncrementFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *ViewCustomerAutoIncrements, e *ViewCustomerAutoIncrement) error {
	if len(dbm.option.eventViewCustomerAutoIncrementFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventViewCustomerAutoIncrementFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventViewCustomerNoAutoIncrementFunc(ctx context.Context, ef dml.EventFlag, skipEvents bool, ec *ViewCustomerNoAutoIncrements, e *ViewCustomerNoAutoIncrement) error {
	if len(dbm.option.eventViewCustomerNoAutoIncrementFunc[ef]) == 0 || skipEvents {
		return nil
	}
	for _, fn := range dbm.option.eventViewCustomerNoAutoIncrementFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

// NewDBManager returns a goified version of the MySQL/MariaDB table schema for
// the tables:  catalog_product_index_eav_decimal_idx, core_configuration,
// customer_address_entity, customer_entity, dmlgen_types,
// sales_order_status_state, view_customer_auto_increment,
// view_customer_no_auto_increment Auto generated by dmlgen.
func NewDBManager(ctx context.Context, dbmo *DBMOption) (*DBM, error) {
	tbls, err := ddl.NewTables(append([]ddl.TableOption{ddl.WithCreateTable(ctx, TableNameCatalogProductIndexEAVDecimalIDX, "", TableNameCoreConfiguration, "", TableNameCustomerAddressEntity, "", TableNameCustomerEntity, "", TableNameDmlgenTypes, "", TableNameSalesOrderStatusState, "", TableNameViewCustomerAutoIncrement, "", TableNameViewCustomerNoAutoIncrement, "")}, dbmo.TableOptions...)...)
	if err != nil {
		return nil, errors.WithStack(err)
	}
	if dbmo.InitSelectFn == nil {
		dbmo.InitSelectFn = func(s *dml.Select) *dml.Select { return s }
	}
	if dbmo.InitUpdateFn == nil {
		dbmo.InitUpdateFn = func(s *dml.Update) *dml.Update { return s }
	}
	if dbmo.InitDeleteFn == nil {
		dbmo.InitDeleteFn = func(s *dml.Delete) *dml.Delete { return s }
	}
	if dbmo.InitInsertFn == nil {
		dbmo.InitInsertFn = func(s *dml.Insert) *dml.Insert { return s }
	}
	err = tbls.Options(
		ddl.WithQueryDBR(map[string]dml.QueryBuilder{
			"CatalogProductIndexEAVDecimalIDXesSelectAll": dbmo.InitSelectFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Select("*")),
			"CatalogProductIndexEAVDecimalIDXesSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Select("*")).Where(
				dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).In().Tuples(),
			),
			"CatalogProductIndexEAVDecimalIDXSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Select("*")).Where(
				dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).Equal().Tuples(),
			),
			"CatalogProductIndexEAVDecimalIDXUpdateByPK": dbmo.InitUpdateFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Update().Where(
				dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).Equal().Tuples(),
			)),
			"CatalogProductIndexEAVDecimalIDXDeleteByPK": dbmo.InitDeleteFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Delete().Where(
				dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).In().Tuples(),
			)),
			"CatalogProductIndexEAVDecimalIDXInsert":     dbmo.InitInsertFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Insert()),
			"CatalogProductIndexEAVDecimalIDXUpsertByPK": dbmo.InitInsertFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Insert()).OnDuplicateKey(),
			"CoreConfigurationsSelectAll":                dbmo.InitSelectFn(tbls.MustTable(TableNameCoreConfiguration).Select("*")),
			"CoreConfigurationsSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCoreConfiguration).Select("*")).Where(
				dml.Column(`config_id`).In().PlaceHolder(),
			),
			"CoreConfigurationSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCoreConfiguration).Select("*")).Where(
				dml.Column(`config_id`).Equal().PlaceHolder(),
			),
			"CoreConfigurationUpdateByPK": dbmo.InitUpdateFn(tbls.MustTable(TableNameCoreConfiguration).Update().Where(
				dml.Column(`config_id`).Equal().PlaceHolder(),
			)),
			"CoreConfigurationDeleteByPK": dbmo.InitDeleteFn(tbls.MustTable(TableNameCoreConfiguration).Delete().Where(
				dml.Column(`config_id`).In().PlaceHolder(),
			)),
			"CoreConfigurationInsert":          dbmo.InitInsertFn(tbls.MustTable(TableNameCoreConfiguration).Insert()),
			"CoreConfigurationUpsertByPK":      dbmo.InitInsertFn(tbls.MustTable(TableNameCoreConfiguration).Insert()).OnDuplicateKey(),
			"CustomerAddressEntitiesSelectAll": dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerAddressEntity).Select("*")),
			"CustomerAddressEntitiesSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerAddressEntity).Select("*")).Where(
				dml.Column(`entity_id`).In().PlaceHolder(),
			),
			"CustomerAddressEntitySelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerAddressEntity).Select("*")).Where(
				dml.Column(`entity_id`).Equal().PlaceHolder(),
			),
			"CustomerAddressEntityUpdateByPK": dbmo.InitUpdateFn(tbls.MustTable(TableNameCustomerAddressEntity).Update().Where(
				dml.Column(`entity_id`).Equal().PlaceHolder(),
			)),
			"CustomerAddressEntityDeleteByPK": dbmo.InitDeleteFn(tbls.MustTable(TableNameCustomerAddressEntity).Delete().Where(
				dml.Column(`entity_id`).In().PlaceHolder(),
			)),
			"CustomerAddressEntityInsert":     dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerAddressEntity).Insert()),
			"CustomerAddressEntityUpsertByPK": dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerAddressEntity).Insert()).OnDuplicateKey(),
			"CustomerEntitiesSelectAll":       dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerEntity).Select("*")),
			"CustomerEntitiesSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerEntity).Select("*")).Where(
				dml.Column(`entity_id`).In().PlaceHolder(),
			),
			"CustomerEntitySelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerEntity).Select("*")).Where(
				dml.Column(`entity_id`).Equal().PlaceHolder(),
			),
			"CustomerEntityUpdateByPK": dbmo.InitUpdateFn(tbls.MustTable(TableNameCustomerEntity).Update().Where(
				dml.Column(`entity_id`).Equal().PlaceHolder(),
			)),
			"CustomerEntityDeleteByPK": dbmo.InitDeleteFn(tbls.MustTable(TableNameCustomerEntity).Delete().Where(
				dml.Column(`entity_id`).In().PlaceHolder(),
			)),
			"CustomerEntityInsert":     dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerEntity).Insert()),
			"CustomerEntityUpsertByPK": dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerEntity).Insert()).OnDuplicateKey(),
			// <FOREIGN_KEY_QUERIES customer_entity >
			"CustomerAddressEntitiesDeleteByFK": dbmo.InitDeleteFn(tbls.MustTable(TableNameCustomerAddressEntity).Delete().Where(
				dml.Column(`parent_id`).Equal().PlaceHolder(),
			)),
			"CustomerAddressEntitiesSelectByFK": dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerAddressEntity).Select("*").Where(
				dml.Column(`parent_id`).Equal().PlaceHolder(),
			)),
			// </FOREIGN_KEY_QUERIES customer_entity >
			"DmlgenTypesCollectionSelectAll": dbmo.InitSelectFn(tbls.MustTable(TableNameDmlgenTypes).Select("*")),
			"DmlgenTypesCollectionSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameDmlgenTypes).Select("*")).Where(
				dml.Column(`id`).In().PlaceHolder(),
			),
			"DmlgenTypesSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameDmlgenTypes).Select("*")).Where(
				dml.Column(`id`).Equal().PlaceHolder(),
			),
			"DmlgenTypesUpdateByPK": dbmo.InitUpdateFn(tbls.MustTable(TableNameDmlgenTypes).Update().Where(
				dml.Column(`id`).Equal().PlaceHolder(),
			)),
			"DmlgenTypesDeleteByPK": dbmo.InitDeleteFn(tbls.MustTable(TableNameDmlgenTypes).Delete().Where(
				dml.Column(`id`).In().PlaceHolder(),
			)),
			"DmlgenTypesInsert":               dbmo.InitInsertFn(tbls.MustTable(TableNameDmlgenTypes).Insert()),
			"DmlgenTypesUpsertByPK":           dbmo.InitInsertFn(tbls.MustTable(TableNameDmlgenTypes).Insert()).OnDuplicateKey(),
			"SalesOrderStatusStatesSelectAll": dbmo.InitSelectFn(tbls.MustTable(TableNameSalesOrderStatusState).Select("*")),
			"SalesOrderStatusStatesSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameSalesOrderStatusState).Select("*")).Where(
				dml.Columns(`status`, `state`).In().Tuples(),
			),
			"SalesOrderStatusStateSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameSalesOrderStatusState).Select("*")).Where(
				dml.Columns(`status`, `state`).Equal().Tuples(),
			),
			"SalesOrderStatusStateUpdateByPK": dbmo.InitUpdateFn(tbls.MustTable(TableNameSalesOrderStatusState).Update().Where(
				dml.Columns(`status`, `state`).Equal().Tuples(),
			)),
			"SalesOrderStatusStateDeleteByPK": dbmo.InitDeleteFn(tbls.MustTable(TableNameSalesOrderStatusState).Delete().Where(
				dml.Columns(`status`, `state`).In().Tuples(),
			)),
			"SalesOrderStatusStateInsert":         dbmo.InitInsertFn(tbls.MustTable(TableNameSalesOrderStatusState).Insert()),
			"SalesOrderStatusStateUpsertByPK":     dbmo.InitInsertFn(tbls.MustTable(TableNameSalesOrderStatusState).Insert()).OnDuplicateKey(),
			"ViewCustomerAutoIncrementsSelectAll": dbmo.InitSelectFn(tbls.MustTable(TableNameViewCustomerAutoIncrement).Select("*")),
			"ViewCustomerAutoIncrementsSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameViewCustomerAutoIncrement).Select("*")).Where(
				dml.Column(`ce_entity_id`).In().PlaceHolder(),
			),
			"ViewCustomerAutoIncrementSelectByPK": dbmo.InitSelectFn(tbls.MustTable(TableNameViewCustomerAutoIncrement).Select("*")).Where(
				dml.Column(`ce_entity_id`).Equal().PlaceHolder(),
			),
		}),
	)
	if err != nil {
		return nil, err
	}
	if err := tbls.Options(dbmo.TableOptionsAfter...); err != nil {
		return nil, err
	}
	if dbmo.Trace == nil {
		dbmo.Trace = cstrace.NewNoopTracerProvider().Tracer("")
	}
	return &DBM{Tables: tbls, option: *dbmo}, nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CatalogProductIndexEAVDecimalIDX) Copy() *CatalogProductIndexEAVDecimalIDX {
	if e == nil {
		return &CatalogProductIndexEAVDecimalIDX{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CatalogProductIndexEAVDecimalIDX) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(5) {
		switch c := cm.Column(); c {
		case "entity_id", "0":
			cm.Uint32(&e.EntityID)
		case "attribute_id", "1":
			cm.Uint32(&e.AttributeID)
		case "store_id", "2":
			cm.Uint32(&e.StoreID)
		case "source_id", "3":
			cm.Uint32(&e.SourceID)
		case "value", "4":
			cm.Decimal(&e.Value)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CatalogProductIndexEAVDecimalIDX Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

type CatalogProductIndexEAVDecimalIDXLoadArgs struct {
	_Named_Fields_Required struct{}
	EntityID               uint32
	AttributeID            uint32
	StoreID                uint32
	SourceID               uint32
}

func (e *CatalogProductIndexEAVDecimalIDX) Load(ctx context.Context, dbm *DBM, arg CatalogProductIndexEAVDecimalIDXLoadArgs, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXSelectByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs arg.EntityID,arg.AttributeID,arg.StoreID,arg.SourceID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXSelectByPK", opts...).Load(ctx, e, arg.EntityID, arg.AttributeID, arg.StoreID, arg.SourceID); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, nil, e))
}

func (e *CatalogProductIndexEAVDecimalIDX) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXDeleteByPK", opts...).ExecContext(ctx, e.EntityID, e.AttributeID, e.StoreID, e.SourceID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CatalogProductIndexEAVDecimalIDX) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXUpdateByPK", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CatalogProductIndexEAVDecimalIDX) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXInsert", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CatalogProductIndexEAVDecimalIDX) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXUpsertByPK", opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CatalogProductIndexEAVDecimalIDX) Empty() *CatalogProductIndexEAVDecimalIDX {
	*e = CatalogProductIndexEAVDecimalIDX{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *CatalogProductIndexEAVDecimalIDX) IsSet() bool {
	return e.EntityID > 0 && e.AttributeID > 0 && e.StoreID > 0 && e.SourceID > 0
}

// This variable can be set in another file to provide a custom validator.
var validateCatalogProductIndexEAVDecimalIDX func(*CatalogProductIndexEAVDecimalIDX) error

// Validate runs internal consistency tests.
func (e *CatalogProductIndexEAVDecimalIDX) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCatalogProductIndexEAVDecimalIDX != nil {
		return validateCatalogProductIndexEAVDecimalIDX(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CatalogProductIndexEAVDecimalIDX) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"entity_id:", e.EntityID, "\n",
		"attribute_id:", e.AttributeID, "\n",
		"store_id:", e.StoreID, "\n",
		"source_id:", e.SourceID, "\n",
		"value:", e.Value, "\n",
	)
	return int64(n2), err
}

// CatalogProductIndexEAVDecimalIDXes represents a collection type for DB table
// catalog_product_index_eav_decimal_idx
// Not thread safe. Auto generated.
type CatalogProductIndexEAVDecimalIDXes struct {
	Data []*CatalogProductIndexEAVDecimalIDX `json:"data,omitempty"`
}

// NewCatalogProductIndexEAVDecimalIDXes  creates a new initialized collection.
// Auto generated.
func NewCatalogProductIndexEAVDecimalIDXes() *CatalogProductIndexEAVDecimalIDXes {
	return &CatalogProductIndexEAVDecimalIDXes{
		Data: make([]*CatalogProductIndexEAVDecimalIDX, 0, 5),
	}
}

// Append will add a new item at the end of * CatalogProductIndexEAVDecimalIDXes
// . Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Append(n ...*CatalogProductIndexEAVDecimalIDX) *CatalogProductIndexEAVDecimalIDXes {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Clear() *CatalogProductIndexEAVDecimalIDXes {
	if cc == nil {
		*cc = CatalogProductIndexEAVDecimalIDXes{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Cut(i, j int) *CatalogProductIndexEAVDecimalIDXes {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *CatalogProductIndexEAVDecimalIDXes) scanColumns(cm *dml.ColumnMap, e *CatalogProductIndexEAVDecimalIDX) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e CatalogProductIndexEAVDecimalIDX
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next(0) {
			switch c := cm.Column(); c {
			case "entity_id":
				cm = cm.Uint32s(cc.EntityIDs()...)
			case "attribute_id":
				cm = cm.Uint32s(cc.AttributeIDs()...)
			case "store_id":
				cm = cm.Uint32s(cc.StoreIDs()...)
			case "source_id":
				cm = cm.Uint32s(cc.SourceIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CatalogProductIndexEAVDecimalIDXes Column %q not found", c)
			}
		} // end for cm.Next
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

type CatalogProductIndexEAVDecimalIDXesDBLoadArgs struct {
	_Named_Fields_Required struct{}
	EntityID               uint32
	AttributeID            uint32
	StoreID                uint32
	SourceID               uint32
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBLoad(ctx context.Context, dbm *DBM, pkIDs []CatalogProductIndexEAVDecimalIDXesDBLoadArgs, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesDBLoad")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	cc.Clear()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs EntityID,AttributeID,StoreID,SourceID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	cacheKey := "CatalogProductIndexEAVDecimalIDXesSelectAll"
	var args []any
	if len(pkIDs) > 0 {
		args = make([]any, 0, len(pkIDs)*4)
		for _, pk := range pkIDs {
			args = append(args, pk.EntityID)
			args = append(args, pk.AttributeID)
			args = append(args, pk.StoreID)
			args = append(args, pk.SourceID)
		}
		cacheKey = "CatalogProductIndexEAVDecimalIDXesSelectByPK"
	}
	if _, err = dbm.ConnPool.WithCacheKey(cacheKey, opts...).Load(ctx, cc, args...); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, cc, nil))
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXDeleteByPK", opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXUpdateByPK", opts...)
	dbrStmt, err := dbr.Prepare(ctx)
	if err != nil {
		return errors.WithStack(err)
	}
	for _, c := range cc.Data {
		res, err := dbrStmt.ExecContext(ctx, c)
		if err := dbr.ResultCheckFn(TableNameCatalogProductIndexEAVDecimalIDX, 1, res, err); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, cc, nil))
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXInsert", opts...)
	res, err := dbr.ExecContext(ctx, cc)
	if err := dbr.ResultCheckFn(TableNameCatalogProductIndexEAVDecimalIDX, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, cc, nil))
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CatalogProductIndexEAVDecimalIDXUpsertByPK", opts...)
	res, err := dbr.ExecContext(ctx, dml.Qualify("", cc))
	if err := dbr.ResultCheckFn(TableNameCatalogProductIndexEAVDecimalIDX, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Delete(i int) *CatalogProductIndexEAVDecimalIDXes {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CatalogProductIndexEAVDecimalIDX
// . Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Each(f func(*CatalogProductIndexEAVDecimalIDX)) *CatalogProductIndexEAVDecimalIDXes {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Filter(f func(*CatalogProductIndexEAVDecimalIDX) bool) *CatalogProductIndexEAVDecimalIDXes {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Insert(n *CatalogProductIndexEAVDecimalIDX, i int) *CatalogProductIndexEAVDecimalIDXes {
	z := cc.Data // copy the slice header
	z = append(z, &CatalogProductIndexEAVDecimalIDX{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Swap(i, j int) {
	cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i]
}

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// EntityIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) EntityIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.EntityID)
	}
	return ret
}

// AttributeIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) AttributeIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.AttributeID)
	}
	return ret
}

// StoreIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) StoreIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.StoreID)
	}
	return ret
}

// SourceIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) SourceIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.SourceID)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CatalogProductIndexEAVDecimalIDXes) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CatalogProductIndexEAVDecimalIDXes) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CoreConfiguration) Copy() *CoreConfiguration {
	if e == nil {
		return &CoreConfiguration{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *CoreConfiguration) AssignLastInsertID(id int64) {
	e.ConfigID = uint32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CoreConfiguration) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(8) {
		switch c := cm.Column(); c {
		case "config_id", "0":
			cm.Uint32(&e.ConfigID)
		case "scope", "1":
			cm.String(&e.Scope)
		case "scope_id", "2":
			cm.Int32(&e.ScopeID)
		case "expires", "3":
			cm.NullTime(&e.Expires)
		case "path", "storage_location", "config_directory", "4":
			cm.String(&e.Path)
		case "value", "5":
			cm.NullString(&e.Value)
		case "version_ts", "6":
			cm.Time(&e.VersionTs)
		case "version_te", "7":
			cm.Time(&e.VersionTe)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CoreConfiguration Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *CoreConfiguration) Load(ctx context.Context, dbm *DBM, primaryKey uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationSelectByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs primaryKey into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.ConnPool.WithCacheKey("CoreConfigurationSelectByPK", opts...).Load(ctx, e, primaryKey); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, nil, e))
}

func (e *CoreConfiguration) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CoreConfigurationDeleteByPK", opts...).ExecContext(ctx, e.ConfigID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CoreConfiguration) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CoreConfigurationUpdateByPK", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CoreConfiguration) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CoreConfigurationInsert", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CoreConfiguration) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CoreConfigurationUpsertByPK", opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CoreConfiguration) Empty() *CoreConfiguration { *e = CoreConfiguration{}; return e }

// IsSet returns true if the entity has non-empty primary keys.
func (e *CoreConfiguration) IsSet() bool { return e.ConfigID > 0 }

// This variable can be set in another file to provide a custom validator.
var validateCoreConfiguration func(*CoreConfiguration) error

// Validate runs internal consistency tests.
func (e *CoreConfiguration) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCoreConfiguration != nil {
		return validateCoreConfiguration(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CoreConfiguration) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"config_id:", e.ConfigID, "\n",
		"scope:", e.Scope, "\n",
		"scope_id:", e.ScopeID, "\n",
		"expires:", e.Expires, "\n",
		"path:", e.Path, "\n",
		"value:", e.Value, "\n",
		"version_ts:", e.VersionTs, "\n",
		"version_te:", e.VersionTe, "\n",
	)
	return int64(n2), err
}

// CoreConfigurations represents a collection type for DB table
// core_configuration
// Not thread safe. Auto generated.
//easyjson:json
type CoreConfigurations struct {
	Data []*CoreConfiguration `json:"data,omitempty"`
}

// NewCoreConfigurations  creates a new initialized collection. Auto generated.
func NewCoreConfigurations() *CoreConfigurations {
	return &CoreConfigurations{
		Data: make([]*CoreConfiguration, 0, 5),
	}
}

// Append will add a new item at the end of * CoreConfigurations . Auto generated
// via dmlgen.
func (cc *CoreConfigurations) Append(n ...*CoreConfiguration) *CoreConfigurations {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *CoreConfigurations) Clear() *CoreConfigurations {
	if cc == nil {
		*cc = CoreConfigurations{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CoreConfigurations) Cut(i, j int) *CoreConfigurations {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *CoreConfigurations) AssignLastInsertID(id int64) {
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i].AssignLastInsertID(id + int64(i))
	}
}

func (cc *CoreConfigurations) scanColumns(cm *dml.ColumnMap, e *CoreConfiguration) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CoreConfigurations) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e CoreConfiguration
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next(0) {
			switch c := cm.Column(); c {
			case "config_id":
				cm = cm.Uint32s(cc.ConfigIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CoreConfigurations Column %q not found", c)
			}
		} // end for cm.Next
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *CoreConfigurations) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsDBLoad")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	cc.Clear()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs ConfigID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.ConnPool.WithCacheKey("CoreConfigurationsSelectByPK", opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.ConnPool.WithCacheKey("CoreConfigurationsSelectAll", opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, cc, nil))
}

func (cc *CoreConfigurations) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CoreConfigurationDeleteByPK", opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CoreConfigurations) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CoreConfigurationUpdateByPK", opts...)
	dbrStmt, err := dbr.Prepare(ctx)
	if err != nil {
		return errors.WithStack(err)
	}
	for _, c := range cc.Data {
		res, err := dbrStmt.ExecContext(ctx, c)
		if err := dbr.ResultCheckFn(TableNameCoreConfiguration, 1, res, err); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, cc, nil))
}

func (cc *CoreConfigurations) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CoreConfigurationInsert", opts...)
	res, err := dbr.ExecContext(ctx, cc)
	if err := dbr.ResultCheckFn(TableNameCoreConfiguration, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, cc, nil))
}

func (cc *CoreConfigurations) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CoreConfigurationUpsertByPK", opts...)
	res, err := dbr.ExecContext(ctx, dml.Qualify("", cc))
	if err := dbr.ResultCheckFn(TableNameCoreConfiguration, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CoreConfigurations) Delete(i int) *CoreConfigurations {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CoreConfiguration . Auto
// generated via dmlgen.
func (cc *CoreConfigurations) Each(f func(*CoreConfiguration)) *CoreConfigurations {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CoreConfigurations) Filter(f func(*CoreConfiguration) bool) *CoreConfigurations {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CoreConfigurations) Insert(n *CoreConfiguration, i int) *CoreConfigurations {
	z := cc.Data // copy the slice header
	z = append(z, &CoreConfiguration{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CoreConfigurations) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CoreConfigurations) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// ConfigIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CoreConfigurations) ConfigIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.ConfigID)
	}
	return ret
}

// Paths belongs to the column "path" and returns a slice or appends to a slice
// only unique values of that column. The values will be filtered internally in a
// Go map. No DB query gets executed. Auto generated.
func (cc *CoreConfigurations) UniquePaths(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	dupCheck := make(map[string]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.Path] {
			ret = append(ret, e.Path)
			dupCheck[e.Path] = true
		}
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CoreConfigurations) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CoreConfigurations) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CustomerAddressEntity) Copy() *CustomerAddressEntity {
	if e == nil {
		return &CustomerAddressEntity{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *CustomerAddressEntity) AssignLastInsertID(id int64) {
	e.EntityID = uint32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CustomerAddressEntity) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(14) {
		switch c := cm.Column(); c {
		case "entity_id", "0":
			cm.Uint32(&e.EntityID)
		case "increment_id", "1":
			cm.NullString(&e.IncrementID)
		case "parent_id", "2":
			cm.NullUint32(&e.ParentID)
		case "created_at", "3":
			cm.Time(&e.CreatedAt)
		case "updated_at", "4":
			cm.Time(&e.UpdatedAt)
		case "is_active", "5":
			cm.Bool(&e.IsActive)
		case "city", "6":
			cm.String(&e.City)
		case "company", "7":
			cm.NullString(&e.Company)
		case "country_id", "8":
			cm.String(&e.CountryID)
		case "firstname", "9":
			cm.String(&e.Firstname)
		case "lastname", "10":
			cm.String(&e.Lastname)
		case "postcode", "11":
			cm.NullString(&e.Postcode)
		case "region", "12":
			cm.NullString(&e.Region)
		case "street", "13":
			cm.String(&e.Street)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CustomerAddressEntity Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *CustomerAddressEntity) Load(ctx context.Context, dbm *DBM, primaryKey uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitySelectByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs primaryKey into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntitySelectByPK", opts...).Load(ctx, e, primaryKey); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, nil, e))
}

func (e *CustomerAddressEntity) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntityDeleteByPK", opts...).ExecContext(ctx, e.EntityID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerAddressEntity) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntityUpdateByPK", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerAddressEntity) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntityInsert", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerAddressEntity) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntityUpsertByPK", opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CustomerAddressEntity) Empty() *CustomerAddressEntity {
	*e = CustomerAddressEntity{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *CustomerAddressEntity) IsSet() bool { return e.EntityID > 0 }

// This variable can be set in another file to provide a custom validator.
var validateCustomerAddressEntity func(*CustomerAddressEntity) error

// Validate runs internal consistency tests.
func (e *CustomerAddressEntity) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCustomerAddressEntity != nil {
		return validateCustomerAddressEntity(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CustomerAddressEntity) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"entity_id:", e.EntityID, "\n",
		"increment_id:", e.IncrementID, "\n",
		"parent_id:", e.ParentID, "\n",
		"created_at:", e.CreatedAt, "\n",
		"updated_at:", e.UpdatedAt, "\n",
		"is_active:", e.IsActive, "\n",
		"city:", e.City, "\n",
		"company:", e.Company, "\n",
		"country_id:", e.CountryID, "\n",
		"firstname:", e.Firstname, "\n",
		"lastname:", e.Lastname, "\n",
		"postcode:", e.Postcode, "\n",
		"region:", e.Region, "\n",
		"street:", e.Street, "\n",
	)
	return int64(n2), err
}

// CustomerAddressEntities represents a collection type for DB table
// customer_address_entity
// Not thread safe. Auto generated.
//easyjson:json
type CustomerAddressEntities struct {
	Data []*CustomerAddressEntity `json:"data,omitempty"`
}

// NewCustomerAddressEntities  creates a new initialized collection. Auto
// generated.
func NewCustomerAddressEntities() *CustomerAddressEntities {
	return &CustomerAddressEntities{
		Data: make([]*CustomerAddressEntity, 0, 5),
	}
}

// Append will add a new item at the end of * CustomerAddressEntities . Auto
// generated via dmlgen.
func (cc *CustomerAddressEntities) Append(n ...*CustomerAddressEntity) *CustomerAddressEntities {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Clear() *CustomerAddressEntities {
	if cc == nil {
		*cc = CustomerAddressEntities{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Cut(i, j int) *CustomerAddressEntities {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *CustomerAddressEntities) AssignLastInsertID(id int64) {
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i].AssignLastInsertID(id + int64(i))
	}
}

func (cc *CustomerAddressEntities) scanColumns(cm *dml.ColumnMap, e *CustomerAddressEntity) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CustomerAddressEntities) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e CustomerAddressEntity
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next(0) {
			switch c := cm.Column(); c {
			case "entity_id":
				cm = cm.Uint32s(cc.EntityIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CustomerAddressEntities Column %q not found", c)
			}
		} // end for cm.Next
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *CustomerAddressEntities) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesDBLoad")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	cc.Clear()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs EntityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntitiesSelectByPK", opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntitiesSelectAll", opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, cc, nil))
}

func (cc *CustomerAddressEntities) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntityDeleteByPK", opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerAddressEntities) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CustomerAddressEntityUpdateByPK", opts...)
	dbrStmt, err := dbr.Prepare(ctx)
	if err != nil {
		return errors.WithStack(err)
	}
	for _, c := range cc.Data {
		res, err := dbrStmt.ExecContext(ctx, c)
		if err := dbr.ResultCheckFn(TableNameCustomerAddressEntity, 1, res, err); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, cc, nil))
}

func (cc *CustomerAddressEntities) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CustomerAddressEntityInsert", opts...)
	res, err := dbr.ExecContext(ctx, cc)
	if err := dbr.ResultCheckFn(TableNameCustomerAddressEntity, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, cc, nil))
}

func (cc *CustomerAddressEntities) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CustomerAddressEntityUpsertByPK", opts...)
	res, err := dbr.ExecContext(ctx, dml.Qualify("", cc))
	if err := dbr.ResultCheckFn(TableNameCustomerAddressEntity, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Delete(i int) *CustomerAddressEntities {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CustomerAddressEntity . Auto
// generated via dmlgen.
func (cc *CustomerAddressEntities) Each(f func(*CustomerAddressEntity)) *CustomerAddressEntities {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Filter(f func(*CustomerAddressEntity) bool) *CustomerAddressEntities {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Insert(n *CustomerAddressEntity, i int) *CustomerAddressEntities {
	z := cc.Data // copy the slice header
	z = append(z, &CustomerAddressEntity{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// EntityIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CustomerAddressEntities) EntityIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.EntityID)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CustomerAddressEntities) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CustomerAddressEntities) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

func (r *customerEntityRelations) DeleteCustomerAddressEntities(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) error {
	dbr := dbm.ConnPool.WithCacheKey("CustomerAddressEntitiesDeleteByFK", opts...)
	res, err := dbr.ExecContext(ctx, r.parent.EntityID)
	err = dbr.ResultCheckFn(TableNameCustomerAddressEntity, len(r.CustomerAddressEntities.Data), res, err)
	if err == nil && r.CustomerAddressEntities != nil {
		r.CustomerAddressEntities.Clear()
	}
	return errors.WithStack(err)
}

func (r *customerEntityRelations) InsertCustomerAddressEntities(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) error {
	if r.CustomerAddressEntities == nil || len(r.CustomerAddressEntities.Data) == 0 {
		return nil
	}
	for _, e2 := range r.CustomerAddressEntities.Data {
		e2.ParentID = null.MakeUint32(uint32(r.parent.EntityID))
	}
	return errors.WithStack(r.CustomerAddressEntities.DBInsert(ctx, dbm, opts...))
}

func (r *customerEntityRelations) UpdateCustomerAddressEntities(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	if r.CustomerAddressEntities == nil || len(r.CustomerAddressEntities.Data) == 0 {
		dbr := dbm.ConnPool.WithCacheKey("CustomerAddressEntitiesDeleteByFK", opts...)
		res, err := dbr.ExecContext(ctx, r.parent.EntityID)
		return dbr.ResultCheckFn(TableNameCustomerAddressEntity, -1, res, errors.WithStack(err))
	}
	for _, e2 := range r.CustomerAddressEntities.Data {
		e2.ParentID = null.MakeUint32(uint32(r.parent.EntityID))
	}
	err = r.CustomerAddressEntities.DBUpdate(ctx, dbm, opts...)
	return errors.WithStack(err)
}

func (r *customerEntityRelations) LoadCustomerAddressEntities(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (rowCount uint64, err error) {
	if r.CustomerAddressEntities == nil {
		r.CustomerAddressEntities = &CustomerAddressEntities{}
	}
	r.CustomerAddressEntities.Clear()
	rowCount, err = dbm.ConnPool.WithCacheKey("CustomerAddressEntitiesSelectByFK", opts...).Load(ctx, r.CustomerAddressEntities, r.parent.EntityID)
	return rowCount, errors.WithStack(err)
}

func (r *customerEntityRelations) InsertAll(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) error {
	if err := r.InsertCustomerAddressEntities(ctx, dbm, opts...); err != nil {
		return errors.WithStack(err)
	}
	return nil
}

func (r *customerEntityRelations) LoadAll(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	if _, err = r.LoadCustomerAddressEntities(ctx, dbm, opts...); err != nil {
		return errors.WithStack(err)
	}
	return nil
}

func (r *customerEntityRelations) UpdateAll(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) error {
	if err := r.UpdateCustomerAddressEntities(ctx, dbm, opts...); err != nil {
		return errors.WithStack(err)
	}
	return nil
}

func (r *customerEntityRelations) DeleteAll(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) error {
	if err := r.DeleteCustomerAddressEntities(ctx, dbm, opts...); err != nil {
		return errors.WithStack(err)
	}
	return nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CustomerEntity) Copy() *CustomerEntity {
	if e == nil {
		return &CustomerEntity{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *CustomerEntity) AssignLastInsertID(id int64) {
	e.EntityID = uint32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CustomerEntity) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(18) {
		switch c := cm.Column(); c {
		case "entity_id", "0":
			cm.Uint32(&e.EntityID)
		case "website_id", "1":
			cm.NullUint32(&e.WebsiteID)
		case "email", "2":
			cm.NullString(&e.Email)
		case "group_id", "3":
			cm.Uint32(&e.GroupID)
		case "store_id", "4":
			cm.NullUint32(&e.StoreID)
		case "created_at", "5":
			cm.Time(&e.CreatedAt)
		case "updated_at", "6":
			cm.Time(&e.UpdatedAt)
		case "is_active", "7":
			cm.Bool(&e.IsActive)
		case "created_in", "8":
			cm.NullString(&e.CreatedIn)
		case "firstname", "9":
			cm.NullString(&e.Firstname)
		case "lastname", "10":
			cm.NullString(&e.Lastname)
		case "dob", "11":
			cm.NullTime(&e.Dob)
		case "password_hash", "12":
			cm.NullString(&e.passwordHash)
		case "rp_token", "13":
			cm.NullString(&e.RpToken)
		case "rp_token_created_at", "14":
			cm.NullTime(&e.RpTokenCreatedAt)
		case "default_billing", "15":
			cm.NullUint32(&e.DefaultBilling)
		case "default_shipping", "16":
			cm.NullUint32(&e.DefaultShipping)
		case "gender", "17":
			cm.NullUint32(&e.Gender)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CustomerEntity Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *CustomerEntity) Load(ctx context.Context, dbm *DBM, primaryKey uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitySelectByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	e.setRelationParent()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs primaryKey into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.ConnPool.WithCacheKey("CustomerEntitySelectByPK", opts...).Load(ctx, e, primaryKey); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, nil, e))
}

func (e *CustomerEntity) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	e.setRelationParent()
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerEntityDeleteByPK", opts...).ExecContext(ctx, e.EntityID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerEntity) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	e.setRelationParent()
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerEntityUpdateByPK", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerEntity) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	e.setRelationParent()
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerEntityInsert", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerEntity) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	e.setRelationParent()
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerEntityUpsertByPK", opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CustomerEntity) Empty() *CustomerEntity { *e = CustomerEntity{}; return e }

// IsSet returns true if the entity has non-empty primary keys.
func (e *CustomerEntity) IsSet() bool { return e.EntityID > 0 }

// Set PasswordHash  sets the data for a private and security sensitive field.
func (e *CustomerEntity) SetPasswordHash(d null.String) *CustomerEntity {
	e.passwordHash = d
	return e
}

// Get PasswordHash  returns the data from a private and security sensitive
// field.
func (e *CustomerEntity) GetPasswordHash() null.String {
	return e.passwordHash
}

// This variable can be set in another file to provide a custom validator.
var validateCustomerEntity func(*CustomerEntity) error

// Validate runs internal consistency tests.
func (e *CustomerEntity) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCustomerEntity != nil {
		return validateCustomerEntity(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CustomerEntity) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"entity_id:", e.EntityID, "\n",
		"website_id:", e.WebsiteID, "\n",
		"email:", e.Email, "\n",
		"group_id:", e.GroupID, "\n",
		"store_id:", e.StoreID, "\n",
		"created_at:", e.CreatedAt, "\n",
		"updated_at:", e.UpdatedAt, "\n",
		"is_active:", e.IsActive, "\n",
		"created_in:", e.CreatedIn, "\n",
		"firstname:", e.Firstname, "\n",
		"lastname:", e.Lastname, "\n",
		"dob:", e.Dob, "\n",
		"rp_token:", e.RpToken, "\n",
		"rp_token_created_at:", e.RpTokenCreatedAt, "\n",
		"default_billing:", e.DefaultBilling, "\n",
		"default_shipping:", e.DefaultShipping, "\n",
		"gender:", e.Gender, "\n",
	)
	return int64(n2), err
}

// CustomerEntities represents a collection type for DB table customer_entity
// Not thread safe. Auto generated.
//easyjson:json
type CustomerEntities struct {
	Data []*CustomerEntity `json:"data,omitempty"`
}

// NewCustomerEntities  creates a new initialized collection. Auto generated.
func NewCustomerEntities() *CustomerEntities {
	return &CustomerEntities{
		Data: make([]*CustomerEntity, 0, 5),
	}
}

// Append will add a new item at the end of * CustomerEntities . Auto generated
// via dmlgen.
func (cc *CustomerEntities) Append(n ...*CustomerEntity) *CustomerEntities {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *CustomerEntities) Clear() *CustomerEntities {
	if cc == nil {
		*cc = CustomerEntities{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CustomerEntities) Cut(i, j int) *CustomerEntities {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *CustomerEntities) AssignLastInsertID(id int64) {
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i].AssignLastInsertID(id + int64(i))
	}
}

func (cc *CustomerEntities) scanColumns(cm *dml.ColumnMap, e *CustomerEntity) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CustomerEntities) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e CustomerEntity
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next(0) {
			switch c := cm.Column(); c {
			case "entity_id":
				cm = cm.Uint32s(cc.EntityIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CustomerEntities Column %q not found", c)
			}
		} // end for cm.Next
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *CustomerEntities) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesDBLoad")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	cc.Clear()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs EntityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.ConnPool.WithCacheKey("CustomerEntitiesSelectByPK", opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.ConnPool.WithCacheKey("CustomerEntitiesSelectAll", opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, cc, nil))
}

func (cc *CustomerEntities) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("CustomerEntityDeleteByPK", opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerEntities) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CustomerEntityUpdateByPK", opts...)
	dbrStmt, err := dbr.Prepare(ctx)
	if err != nil {
		return errors.WithStack(err)
	}
	for _, c := range cc.Data {
		res, err := dbrStmt.ExecContext(ctx, c)
		if err := dbr.ResultCheckFn(TableNameCustomerEntity, 1, res, err); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, cc, nil))
}

func (cc *CustomerEntities) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CustomerEntityInsert", opts...)
	res, err := dbr.ExecContext(ctx, cc)
	if err := dbr.ResultCheckFn(TableNameCustomerEntity, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, cc, nil))
}

func (cc *CustomerEntities) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("CustomerEntityUpsertByPK", opts...)
	res, err := dbr.ExecContext(ctx, dml.Qualify("", cc))
	if err := dbr.ResultCheckFn(TableNameCustomerEntity, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CustomerEntities) Delete(i int) *CustomerEntities {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CustomerEntity . Auto generated
// via dmlgen.
func (cc *CustomerEntities) Each(f func(*CustomerEntity)) *CustomerEntities {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CustomerEntities) Filter(f func(*CustomerEntity) bool) *CustomerEntities {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CustomerEntities) Insert(n *CustomerEntity, i int) *CustomerEntities {
	z := cc.Data // copy the slice header
	z = append(z, &CustomerEntity{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerEntities) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerEntities) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// EntityIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CustomerEntities) EntityIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.EntityID)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CustomerEntities) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CustomerEntities) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *DmlgenTypes) Copy() *DmlgenTypes {
	if e == nil {
		return &DmlgenTypes{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *DmlgenTypes) AssignLastInsertID(id int64) {
	e.ID = int32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *DmlgenTypes) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(41) {
		switch c := cm.Column(); c {
		case "id", "0":
			cm.Int32(&e.ID)
		case "col_bigint_1", "1":
			cm.NullInt64(&e.ColBigint1)
		case "col_bigint_2", "2":
			cm.Int64(&e.ColBigint2)
		case "col_bigint_3", "3":
			cm.NullUint64(&e.ColBigint3)
		case "col_bigint_4", "4":
			cm.Uint64(&e.ColBigint4)
		case "col_blob", "5":
			cm.Byte(&e.ColBlob)
		case "col_date_1", "6":
			cm.NullTime(&e.ColDate1)
		case "col_date_2", "7":
			cm.Time(&e.ColDate2)
		case "col_datetime_1", "8":
			cm.NullTime(&e.ColDatetime1)
		case "col_datetime_2", "9":
			cm.Time(&e.ColDatetime2)
		case "col_decimal_10_1", "10":
			cm.Decimal(&e.ColDecimal101)
		case "col_decimal_12_4", "11":
			cm.Decimal(&e.ColDecimal124)
		case "price_a_12_4", "12":
			cm.Decimal(&e.PriceA124)
		case "price_b_12_4", "13":
			cm.Decimal(&e.PriceB124)
		case "col_decimal_12_3", "14":
			cm.Decimal(&e.ColDecimal123)
		case "col_decimal_20_6", "15":
			cm.Decimal(&e.ColDecimal206)
		case "col_decimal_24_12", "16":
			cm.Decimal(&e.ColDecimal2412)
		case "col_int_1", "17":
			cm.NullInt32(&e.ColInt1)
		case "col_int_2", "18":
			cm.Int32(&e.ColInt2)
		case "col_int_3", "19":
			cm.NullUint32(&e.ColInt3)
		case "col_int_4", "20":
			cm.Uint32(&e.ColInt4)
		case "col_longtext_1", "21":
			cm.NullString(&e.ColLongtext1)
		case "col_longtext_2", "22":
			cm.String(&e.ColLongtext2)
		case "col_mediumblob", "23":
			cm.Byte(&e.ColMediumblob)
		case "col_mediumtext_1", "24":
			cm.NullString(&e.ColMediumtext1)
		case "col_mediumtext_2", "25":
			cm.String(&e.ColMediumtext2)
		case "col_smallint_1", "26":
			cm.NullInt32(&e.ColSmallint1)
		case "col_smallint_2", "27":
			cm.Int32(&e.ColSmallint2)
		case "col_smallint_3", "28":
			cm.NullUint32(&e.ColSmallint3)
		case "col_smallint_4", "29":
			cm.Uint32(&e.ColSmallint4)
		case "has_smallint_5", "30":
			cm.Bool(&e.HasSmallint5)
		case "is_smallint_5", "31":
			cm.NullBool(&e.IsSmallint5)
		case "col_text", "32":
			cm.NullString(&e.ColText)
		case "col_timestamp_1", "33":
			cm.Time(&e.ColTimestamp1)
		case "col_timestamp_2", "34":
			cm.NullTime(&e.ColTimestamp2)
		case "col_tinyint_1", "35":
			cm.Int32(&e.ColTinyint1)
		case "col_varchar_1", "36":
			cm.String(&e.ColVarchar1)
		case "col_varchar_100", "37":
			cm.NullString(&e.ColVarchar100)
		case "col_varchar_16", "38":
			cm.String(&e.ColVarchar16)
		case "col_char_1", "39":
			cm.NullString(&e.ColChar1)
		case "col_char_2", "40":
			cm.String(&e.ColChar2)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] DmlgenTypes Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *DmlgenTypes) Load(ctx context.Context, dbm *DBM, primaryKey int32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesSelectByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs primaryKey into the context as value to search for a cache entry in the event function.
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.ConnPool.WithCacheKey("DmlgenTypesSelectByPK", opts...).Load(ctx, e, primaryKey); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, nil, e))
}

func (e *DmlgenTypes) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("DmlgenTypesDeleteByPK", opts...).ExecContext(ctx, e.ID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *DmlgenTypes) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("DmlgenTypesUpdateByPK", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *DmlgenTypes) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("DmlgenTypesInsert", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *DmlgenTypes) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("DmlgenTypesUpsertByPK", opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *DmlgenTypes) Empty() *DmlgenTypes { *e = DmlgenTypes{}; return e }

// IsSet returns true if the entity has non-empty primary keys.
func (e *DmlgenTypes) IsSet() bool { return e.ID != 0 }

// This variable can be set in another file to provide a custom validator.
var validateDmlgenTypes func(*DmlgenTypes) error

// Validate runs internal consistency tests.
func (e *DmlgenTypes) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateDmlgenTypes != nil {
		return validateDmlgenTypes(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *DmlgenTypes) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"id:", e.ID, "\n",
		"col_bigint_1:", e.ColBigint1, "\n",
		"col_bigint_2:", e.ColBigint2, "\n",
		"col_bigint_3:", e.ColBigint3, "\n",
		"col_bigint_4:", e.ColBigint4, "\n",
		"col_blob:", e.ColBlob, "\n",
		"col_date_1:", e.ColDate1, "\n",
		"col_date_2:", e.ColDate2, "\n",
		"col_datetime_1:", e.ColDatetime1, "\n",
		"col_datetime_2:", e.ColDatetime2, "\n",
		"col_decimal_10_1:", e.ColDecimal101, "\n",
		"col_decimal_12_4:", e.ColDecimal124, "\n",
		"price_a_12_4:", e.PriceA124, "\n",
		"price_b_12_4:", e.PriceB124, "\n",
		"col_decimal_12_3:", e.ColDecimal123, "\n",
		"col_decimal_20_6:", e.ColDecimal206, "\n",
		"col_decimal_24_12:", e.ColDecimal2412, "\n",
		"col_int_1:", e.ColInt1, "\n",
		"col_int_2:", e.ColInt2, "\n",
		"col_int_3:", e.ColInt3, "\n",
		"col_int_4:", e.ColInt4, "\n",
		"col_longtext_1:", e.ColLongtext1, "\n",
		"col_longtext_2:", e.ColLongtext2, "\n",
		"col_mediumblob:", e.ColMediumblob, "\n",
		"col_mediumtext_1:", e.ColMediumtext1, "\n",
		"col_mediumtext_2:", e.ColMediumtext2, "\n",
		"col_smallint_1:", e.ColSmallint1, "\n",
		"col_smallint_2:", e.ColSmallint2, "\n",
		"col_smallint_3:", e.ColSmallint3, "\n",
		"col_smallint_4:", e.ColSmallint4, "\n",
		"has_smallint_5:", e.HasSmallint5, "\n",
		"is_smallint_5:", e.IsSmallint5, "\n",
		"col_text:", e.ColText, "\n",
		"col_timestamp_1:", e.ColTimestamp1, "\n",
		"col_timestamp_2:", e.ColTimestamp2, "\n",
		"col_tinyint_1:", e.ColTinyint1, "\n",
		"col_varchar_1:", e.ColVarchar1, "\n",
		"col_varchar_100:", e.ColVarchar100, "\n",
		"col_varchar_16:", e.ColVarchar16, "\n",
		"col_char_1:", e.ColChar1, "\n",
		"col_char_2:", e.ColChar2, "\n",
	)
	return int64(n2), err
}

// DmlgenTypesCollection represents a collection type for DB table dmlgen_types
// Not thread safe. Auto generated.
// // Just another comment.
//easyjson:json
type DmlgenTypesCollection struct {
	Data []*DmlgenTypes `json:"data,omitempty"`
}

// NewDmlgenTypesCollection  creates a new initialized collection. Auto
// generated.
func NewDmlgenTypesCollection() *DmlgenTypesCollection {
	return &DmlgenTypesCollection{
		Data: make([]*DmlgenTypes, 0, 5),
	}
}

// Append will add a new item at the end of * DmlgenTypesCollection . Auto
// generated via dmlgen.
func (cc *DmlgenTypesCollection) Append(n ...*DmlgenTypes) *DmlgenTypesCollection {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Clear() *DmlgenTypesCollection {
	if cc == nil {
		*cc = DmlgenTypesCollection{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Cut(i, j int) *DmlgenTypesCollection {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *DmlgenTypesCollection) AssignLastInsertID(id int64) {
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i].AssignLastInsertID(id + int64(i))
	}
}

func (cc *DmlgenTypesCollection) scanColumns(cm *dml.ColumnMap, e *DmlgenTypes) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *DmlgenTypesCollection) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e DmlgenTypes
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next(0) {
			switch c := cm.Column(); c {
			case "id":
				cm = cm.Int32s(cc.IDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] DmlgenTypesCollection Column %q not found", c)
			}
		} // end for cm.Next
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *DmlgenTypesCollection) DBLoad(ctx context.Context, dbm *DBM, pkIDs []int32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionDBLoad")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	cc.Clear()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs ID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.ConnPool.WithCacheKey("DmlgenTypesCollectionSelectByPK", opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.ConnPool.WithCacheKey("DmlgenTypesCollectionSelectAll", opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, cc, nil))
}

func (cc *DmlgenTypesCollection) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("DmlgenTypesDeleteByPK", opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *DmlgenTypesCollection) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("DmlgenTypesUpdateByPK", opts...)
	dbrStmt, err := dbr.Prepare(ctx)
	if err != nil {
		return errors.WithStack(err)
	}
	for _, c := range cc.Data {
		res, err := dbrStmt.ExecContext(ctx, c)
		if err := dbr.ResultCheckFn(TableNameDmlgenTypes, 1, res, err); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, cc, nil))
}

func (cc *DmlgenTypesCollection) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("DmlgenTypesInsert", opts...)
	res, err := dbr.ExecContext(ctx, cc)
	if err := dbr.ResultCheckFn(TableNameDmlgenTypes, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, cc, nil))
}

func (cc *DmlgenTypesCollection) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("DmlgenTypesUpsertByPK", opts...)
	res, err := dbr.ExecContext(ctx, dml.Qualify("", cc))
	if err := dbr.ResultCheckFn(TableNameDmlgenTypes, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Delete(i int) *DmlgenTypesCollection {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* DmlgenTypes . Auto generated via
// dmlgen.
func (cc *DmlgenTypesCollection) Each(f func(*DmlgenTypes)) *DmlgenTypesCollection {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Filter(f func(*DmlgenTypes) bool) *DmlgenTypesCollection {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Insert(n *DmlgenTypes, i int) *DmlgenTypesCollection {
	z := cc.Data // copy the slice header
	z = append(z, &DmlgenTypes{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// IDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *DmlgenTypesCollection) IDs(ret ...int32) []int32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]int32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.ID)
	}
	return ret
}

// ColDate2s belongs to the column "col_date_2" and returns a slice or appends to
// a slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColDate2s(ret ...time.Time) []time.Time {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]time.Time, 0, len(cc.Data))
	}
	dupCheck := make(map[time.Time]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColDate2] {
			ret = append(ret, e.ColDate2)
			dupCheck[e.ColDate2] = true
		}
	}
	return ret
}

// PriceA124s belongs to the column "price_a_12_4" and returns a slice or appends
// to a slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniquePriceA124s(ret ...null.Decimal) []null.Decimal {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]null.Decimal, 0, len(cc.Data))
	}
	dupCheck := make(map[null.Decimal]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.PriceA124] {
			ret = append(ret, e.PriceA124)
			dupCheck[e.PriceA124] = true
		}
	}
	return ret
}

// ColInt1s belongs to the column "col_int_1" and returns a slice or appends to a
// slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColInt1s(ret ...int32) []int32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]int32, 0, len(cc.Data))
	}
	dupCheck := make(map[int32]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColInt1.Int32] {
			ret = append(ret, e.ColInt1.Int32)
			dupCheck[e.ColInt1.Int32] = true
		}
	}
	return ret
}

// ColInt2s belongs to the column "col_int_2" and returns a slice or appends to a
// slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColInt2s(ret ...int32) []int32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]int32, 0, len(cc.Data))
	}
	dupCheck := make(map[int32]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColInt2] {
			ret = append(ret, e.ColInt2)
			dupCheck[e.ColInt2] = true
		}
	}
	return ret
}

// HasSmallint5s belongs to the column "has_smallint_5" and returns a slice or
// appends to a slice only unique values of that column. The values will be
// filtered internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueHasSmallint5s(ret ...bool) []bool {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]bool, 0, len(cc.Data))
	}
	dupCheck := make(map[bool]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.HasSmallint5] {
			ret = append(ret, e.HasSmallint5)
			dupCheck[e.HasSmallint5] = true
		}
	}
	return ret
}

// ColVarchar100s belongs to the column "col_varchar_100" and returns a slice or
// appends to a slice only unique values of that column. The values will be
// filtered internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColVarchar100s(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	dupCheck := make(map[string]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColVarchar100.Data] {
			ret = append(ret, e.ColVarchar100.Data)
			dupCheck[e.ColVarchar100.Data] = true
		}
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *DmlgenTypesCollection) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *DmlgenTypesCollection) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *SalesOrderStatusState) Copy() *SalesOrderStatusState {
	if e == nil {
		return &SalesOrderStatusState{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *SalesOrderStatusState) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(4) {
		switch c := cm.Column(); c {
		case "status", "0":
			cm.String(&e.Status)
		case "state", "1":
			cm.String(&e.State)
		case "is_default", "2":
			cm.Bool(&e.IsDefault)
		case "visible_on_front", "3":
			cm.Uint32(&e.VisibleOnFront)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] SalesOrderStatusState Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

type SalesOrderStatusStateLoadArgs struct {
	_Named_Fields_Required struct{}
	Status                 string
	State                  string
}

func (e *SalesOrderStatusState) Load(ctx context.Context, dbm *DBM, arg SalesOrderStatusStateLoadArgs, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateSelectByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs arg.Status,arg.State into the context as value to search for a cache entry in the event function.
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.ConnPool.WithCacheKey("SalesOrderStatusStateSelectByPK", opts...).Load(ctx, e, arg.Status, arg.State); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, nil, e))
}

func (e *SalesOrderStatusState) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("SalesOrderStatusStateDeleteByPK", opts...).ExecContext(ctx, e.Status, e.State); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *SalesOrderStatusState) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("SalesOrderStatusStateUpdateByPK", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *SalesOrderStatusState) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("SalesOrderStatusStateInsert", opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *SalesOrderStatusState) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("SalesOrderStatusStateUpsertByPK", opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *SalesOrderStatusState) Empty() *SalesOrderStatusState {
	*e = SalesOrderStatusState{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *SalesOrderStatusState) IsSet() bool { return e.Status != "" && e.State != "" }

// This variable can be set in another file to provide a custom validator.
var validateSalesOrderStatusState func(*SalesOrderStatusState) error

// Validate runs internal consistency tests.
func (e *SalesOrderStatusState) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateSalesOrderStatusState != nil {
		return validateSalesOrderStatusState(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *SalesOrderStatusState) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"status:", e.Status, "\n",
		"state:", e.State, "\n",
		"is_default:", e.IsDefault, "\n",
		"visible_on_front:", e.VisibleOnFront, "\n",
	)
	return int64(n2), err
}

// SalesOrderStatusStates represents a collection type for DB table
// sales_order_status_state
// Not thread safe. Auto generated.
//easyjson:json
type SalesOrderStatusStates struct {
	Data []*SalesOrderStatusState `json:"data,omitempty"`
}

// NewSalesOrderStatusStates  creates a new initialized collection. Auto
// generated.
func NewSalesOrderStatusStates() *SalesOrderStatusStates {
	return &SalesOrderStatusStates{
		Data: make([]*SalesOrderStatusState, 0, 5),
	}
}

// Append will add a new item at the end of * SalesOrderStatusStates . Auto
// generated via dmlgen.
func (cc *SalesOrderStatusStates) Append(n ...*SalesOrderStatusState) *SalesOrderStatusStates {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Clear() *SalesOrderStatusStates {
	if cc == nil {
		*cc = SalesOrderStatusStates{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Cut(i, j int) *SalesOrderStatusStates {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *SalesOrderStatusStates) scanColumns(cm *dml.ColumnMap, e *SalesOrderStatusState) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *SalesOrderStatusStates) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e SalesOrderStatusState
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next(0) {
			switch c := cm.Column(); c {
			case "status":
				cm = cm.Strings(cc.Statuss()...)
			case "state":
				cm = cm.Strings(cc.States()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] SalesOrderStatusStates Column %q not found", c)
			}
		} // end for cm.Next
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

type SalesOrderStatusStatesDBLoadArgs struct {
	_Named_Fields_Required struct{}
	Status                 string
	State                  string
}

func (cc *SalesOrderStatusStates) DBLoad(ctx context.Context, dbm *DBM, pkIDs []SalesOrderStatusStatesDBLoadArgs, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesDBLoad")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	cc.Clear()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs Status,State into the context as value to search for a cache entry in the event function.
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	cacheKey := "SalesOrderStatusStatesSelectAll"
	var args []any
	if len(pkIDs) > 0 {
		args = make([]any, 0, len(pkIDs)*2)
		for _, pk := range pkIDs {
			args = append(args, pk.Status)
			args = append(args, pk.State)
		}
		cacheKey = "SalesOrderStatusStatesSelectByPK"
	}
	if _, err = dbm.ConnPool.WithCacheKey(cacheKey, opts...).Load(ctx, cc, args...); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, cc, nil))
}

func (cc *SalesOrderStatusStates) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesDeleteByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeDelete, qo.SkipEvents, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.ConnPool.WithCacheKey("SalesOrderStatusStateDeleteByPK", opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterDelete, qo.SkipEvents, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *SalesOrderStatusStates) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesUpdateByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpdate, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("SalesOrderStatusStateUpdateByPK", opts...)
	dbrStmt, err := dbr.Prepare(ctx)
	if err != nil {
		return errors.WithStack(err)
	}
	for _, c := range cc.Data {
		res, err := dbrStmt.ExecContext(ctx, c)
		if err := dbr.ResultCheckFn(TableNameSalesOrderStatusState, 1, res, err); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpdate, qo.SkipEvents, cc, nil))
}

func (cc *SalesOrderStatusStates) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesInsert")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeInsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("SalesOrderStatusStateInsert", opts...)
	res, err := dbr.ExecContext(ctx, cc)
	if err := dbr.ResultCheckFn(TableNameSalesOrderStatusState, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterInsert, qo.SkipEvents, cc, nil))
}

func (cc *SalesOrderStatusStates) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesUpsertByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	if err := dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpsert, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	dbr := dbm.ConnPool.WithCacheKey("SalesOrderStatusStateUpsertByPK", opts...)
	res, err := dbr.ExecContext(ctx, dml.Qualify("", cc))
	if err := dbr.ResultCheckFn(TableNameSalesOrderStatusState, len(cc.Data), res, err); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpsert, qo.SkipEvents, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Delete(i int) *SalesOrderStatusStates {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* SalesOrderStatusState . Auto
// generated via dmlgen.
func (cc *SalesOrderStatusStates) Each(f func(*SalesOrderStatusState)) *SalesOrderStatusStates {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Filter(f func(*SalesOrderStatusState) bool) *SalesOrderStatusStates {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Insert(n *SalesOrderStatusState, i int) *SalesOrderStatusStates {
	z := cc.Data // copy the slice header
	z = append(z, &SalesOrderStatusState{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// Statuss returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *SalesOrderStatusStates) Statuss(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.Status)
	}
	return ret
}

// States returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *SalesOrderStatusStates) States(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.State)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *SalesOrderStatusStates) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *SalesOrderStatusStates) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *ViewCustomerAutoIncrement) Copy() *ViewCustomerAutoIncrement {
	if e == nil {
		return &ViewCustomerAutoIncrement{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *ViewCustomerAutoIncrement) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(5) {
		switch c := cm.Column(); c {
		case "ce_entity_id", "0":
			cm.Uint32(&e.CeEntityID)
		case "email", "1":
			cm.NullString(&e.Email)
		case "firstname", "2":
			cm.String(&e.Firstname)
		case "lastname", "3":
			cm.String(&e.Lastname)
		case "city", "4":
			cm.String(&e.City)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] ViewCustomerAutoIncrement Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *ViewCustomerAutoIncrement) Load(ctx context.Context, dbm *DBM, primaryKey uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "ViewCustomerAutoIncrementSelectByPK")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("ViewCustomerAutoIncrement can't be nil")
	}
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs primaryKey into the context as value to search for a cache entry in the event function.
	if err = dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.ConnPool.WithCacheKey("ViewCustomerAutoIncrementSelectByPK", opts...).Load(ctx, e, primaryKey); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, nil, e))
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *ViewCustomerAutoIncrement) Empty() *ViewCustomerAutoIncrement {
	*e = ViewCustomerAutoIncrement{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *ViewCustomerAutoIncrement) IsSet() bool { return e.CeEntityID > 0 }

// This variable can be set in another file to provide a custom validator.
var validateViewCustomerAutoIncrement func(*ViewCustomerAutoIncrement) error

// Validate runs internal consistency tests.
func (e *ViewCustomerAutoIncrement) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateViewCustomerAutoIncrement != nil {
		return validateViewCustomerAutoIncrement(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *ViewCustomerAutoIncrement) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"ce_entity_id:", e.CeEntityID, "\n",
		"email:", e.Email, "\n",
		"firstname:", e.Firstname, "\n",
		"lastname:", e.Lastname, "\n",
		"city:", e.City, "\n",
	)
	return int64(n2), err
}

// ViewCustomerAutoIncrements represents a collection type for DB table
// view_customer_auto_increment
// Not thread safe. Auto generated.
//easyjson:json
type ViewCustomerAutoIncrements struct {
	Data []*ViewCustomerAutoIncrement `json:"data,omitempty"`
}

// NewViewCustomerAutoIncrements  creates a new initialized collection. Auto
// generated.
func NewViewCustomerAutoIncrements() *ViewCustomerAutoIncrements {
	return &ViewCustomerAutoIncrements{
		Data: make([]*ViewCustomerAutoIncrement, 0, 5),
	}
}

// Append will add a new item at the end of * ViewCustomerAutoIncrements . Auto
// generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Append(n ...*ViewCustomerAutoIncrement) *ViewCustomerAutoIncrements {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Clear() *ViewCustomerAutoIncrements {
	if cc == nil {
		*cc = ViewCustomerAutoIncrements{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Cut(i, j int) *ViewCustomerAutoIncrements {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *ViewCustomerAutoIncrements) scanColumns(cm *dml.ColumnMap, e *ViewCustomerAutoIncrement) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *ViewCustomerAutoIncrements) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e ViewCustomerAutoIncrement
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *ViewCustomerAutoIncrements) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "ViewCustomerAutoIncrementsDBLoad")
	defer func() { cstrace.Status(span, err, ""); span.End() }()
	cc.Clear()
	qo := dml.FromContextQueryOptions(ctx)
	// put the IDs CeEntityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagBeforeSelect, qo.SkipEvents, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.ConnPool.WithCacheKey("ViewCustomerAutoIncrementsSelectByPK", opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.ConnPool.WithCacheKey("ViewCustomerAutoIncrementsSelectAll", opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagAfterSelect, qo.SkipEvents, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Delete(i int) *ViewCustomerAutoIncrements {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* ViewCustomerAutoIncrement . Auto
// generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Each(f func(*ViewCustomerAutoIncrement)) *ViewCustomerAutoIncrements {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Filter(f func(*ViewCustomerAutoIncrement) bool) *ViewCustomerAutoIncrements {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Insert(n *ViewCustomerAutoIncrement, i int) *ViewCustomerAutoIncrements {
	z := cc.Data // copy the slice header
	z = append(z, &ViewCustomerAutoIncrement{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// Validate runs internal consistency tests on all items.
func (cc *ViewCustomerAutoIncrements) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *ViewCustomerAutoIncrements) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *ViewCustomerNoAutoIncrement) Copy() *ViewCustomerNoAutoIncrement {
	if e == nil {
		return &ViewCustomerNoAutoIncrement{}
	}
	e2 := *e // for now a shallow copy
	return &e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *ViewCustomerNoAutoIncrement) MapColumns(cm *dml.ColumnMap) error {
	for cm.Next(4) {
		switch c := cm.Column(); c {
		case "email", "0":
			cm.NullString(&e.Email)
		case "firstname", "1":
			cm.String(&e.Firstname)
		case "lastname", "2":
			cm.String(&e.Lastname)
		case "city", "3":
			cm.String(&e.City)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] ViewCustomerNoAutoIncrement Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

// The table/view ViewCustomerNoAutoIncrement does not have a primary key.
// SKipping to generate DML functions based on the PK.

// Empty empties all the fields of the current object. Also known as Reset.
func (e *ViewCustomerNoAutoIncrement) Empty() *ViewCustomerNoAutoIncrement {
	*e = ViewCustomerNoAutoIncrement{}
	return e
}

// This variable can be set in another file to provide a custom validator.
var validateViewCustomerNoAutoIncrement func(*ViewCustomerNoAutoIncrement) error

// Validate runs internal consistency tests.
func (e *ViewCustomerNoAutoIncrement) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateViewCustomerNoAutoIncrement != nil {
		return validateViewCustomerNoAutoIncrement(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *ViewCustomerNoAutoIncrement) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"email:", e.Email, "\n",
		"firstname:", e.Firstname, "\n",
		"lastname:", e.Lastname, "\n",
		"city:", e.City, "\n",
	)
	return int64(n2), err
}

// ViewCustomerNoAutoIncrements represents a collection type for DB table
// view_customer_no_auto_increment
// Not thread safe. Auto generated.
//easyjson:json
type ViewCustomerNoAutoIncrements struct {
	Data []*ViewCustomerNoAutoIncrement `json:"data,omitempty"`
}

// NewViewCustomerNoAutoIncrements  creates a new initialized collection. Auto
// generated.
func NewViewCustomerNoAutoIncrements() *ViewCustomerNoAutoIncrements {
	return &ViewCustomerNoAutoIncrements{
		Data: make([]*ViewCustomerNoAutoIncrement, 0, 5),
	}
}

// Append will add a new item at the end of * ViewCustomerNoAutoIncrements . Auto
// generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Append(n ...*ViewCustomerNoAutoIncrement) *ViewCustomerNoAutoIncrements {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Clear will reset the data slice or create a new type. Useful for reusing the
// underlying backing slice array. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Clear() *ViewCustomerNoAutoIncrements {
	if cc == nil {
		*cc = ViewCustomerNoAutoIncrements{}
		return cc
	}
	if c := cap(cc.Data); c > len(cc.Data) {
		cc.Data = cc.Data[:c]
	}
	for i := 0; i < len(cc.Data); i++ {
		cc.Data[i] = nil
	}
	cc.Data = cc.Data[:0]
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Cut(i, j int) *ViewCustomerNoAutoIncrements {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *ViewCustomerNoAutoIncrements) scanColumns(cm *dml.ColumnMap, e *ViewCustomerNoAutoIncrement) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *ViewCustomerNoAutoIncrements) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for _, e := range cc.Data {
			if err := cc.scanColumns(cm, e); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Clear()
		}
		var e ViewCustomerNoAutoIncrement
		if err := cc.scanColumns(cm, &e); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, &e)
	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

// The table/view ViewCustomerNoAutoIncrements does not have a primary key.
// Skipping to generate DML functions based on the PK.

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Delete(i int) *ViewCustomerNoAutoIncrements {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* ViewCustomerNoAutoIncrement .
// Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Each(f func(*ViewCustomerNoAutoIncrement)) *ViewCustomerNoAutoIncrements {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Filter(f func(*ViewCustomerNoAutoIncrement) bool) *ViewCustomerNoAutoIncrements {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Insert(n *ViewCustomerNoAutoIncrement, i int) *ViewCustomerNoAutoIncrements {
	z := cc.Data // copy the slice header
	z = append(z, &ViewCustomerNoAutoIncrement{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Swap(i, j int) {
	cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i]
}

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// Validate runs internal consistency tests on all items.
func (cc *ViewCustomerNoAutoIncrements) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *ViewCustomerNoAutoIncrements) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}
